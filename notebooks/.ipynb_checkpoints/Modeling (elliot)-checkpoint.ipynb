{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports / Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, explained_variance_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.float_format = '{:.10f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LOANSTATS\n",
    "directory = '../../data/clean/'\n",
    "\n",
    "# FOR TESTING: only load first X rows\n",
    "ls = pd.read_hdf(directory + 'LS_CLEAN.h5', stop=100000)\n",
    "ls.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_Class == 1 (before): 86669\n",
      "OUT_Class == 0 (before): 13331\n",
      "OUT_Class == 1 (after): 13331\n",
      "OUT_Class == 0 (after): 13331\n"
     ]
    }
   ],
   "source": [
    "# THIS IS AN ATTEMPT TO BALANCE THE DATA (because the classes are SO uneven)\n",
    "# removing some of the data RANDOMLY \"should\" not change any of the results\n",
    "# we can do this because we have SO MUCH data\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "ind_TF = ls['OUT_Class'] == 1\n",
    "\n",
    "# \"ind_fp_TF[ind_fp_TF]\" means to take the subest of TRUE indices from \"ind_fp_TF\"\n",
    "# we must use \".index.values\" because we are removing by index\n",
    "drop_ind = np.random.choice(ind_TF[ind_TF].index.values, size=np.sum(ind_TF) - np.sum(~ind_TF), replace=False)\n",
    "\n",
    "print('OUT_Class == 1 (before):', np.sum(ls['OUT_Class'] == 1))\n",
    "print('OUT_Class == 0 (before):', np.sum(ls['OUT_Class'] == 0))\n",
    "ls.drop(drop_ind, axis=0, inplace=True)\n",
    "print('OUT_Class == 1 (after):', np.sum(ls['OUT_Class'] == 1))\n",
    "print('OUT_Class == 0 (after):', np.sum(ls['OUT_Class'] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SET VALUES IN CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_column = 'OUT_Class'\n",
    "\n",
    "# OPTIONS: \"regressor\", \"classifier\"\n",
    "model_type = 'classifier' # assuming data type is also of this type\n",
    "assert model_type in ['regressor', 'classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP OTHER DEPENDENT COLUMN\n",
    "\n",
    "all_dependent_columns = ['OUT_Class', 'OUT_Monthly_Rate_Of_Return', 'OUT_Principle_Repaid_Percentage'] # we may add more later\n",
    "all_dependent_columns.remove(dependent_column)\n",
    "\n",
    "ls_cleaned = ls.drop(all_dependent_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation/modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# (OPTIONAL) SCALE THE DATA USING MIN/MAX - OTHERWISE IT CAN GET WEIRD\n",
    "\n",
    "independent_columns = ls_cleaned.columns.values.tolist()\n",
    "independent_columns.remove(dependent_column)\n",
    "\n",
    "# NaNs are disregarded (this is good)\n",
    "ls_cleaned[independent_columns] = MinMaxScaler().fit_transform(ls_cleaned[independent_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SET VALUES IN CELL BELOW (VERY OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_missing_indicator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE NaNs\n",
    "\n",
    "ls_impute = ls_cleaned.copy()\n",
    "\n",
    "if add_missing_indicator == True:\n",
    "    # I have the following 2 lines so I can run the cell multiple times without messing up the list\n",
    "    independent_columns = ls_cleaned.columns.values.tolist()\n",
    "    independent_columns.remove(dependent_column)\n",
    "    \n",
    "    MI_independent_columns = [col + '_MI' for col in independent_columns]\n",
    "    \n",
    "    # this JUST runs on the columns with missing data (you can change this if needed - it may cause problems)\n",
    "    MI_data = MissingIndicator(features='all').fit_transform(ls_cleaned[independent_columns])\n",
    "    MI_df = pd.DataFrame(data=MI_data, columns=MI_independent_columns)\n",
    "    ls_impute[MI_independent_columns] = MI_df\n",
    "    \n",
    "    independent_columns += MI_independent_columns\n",
    "\n",
    "ls_impute = ls_impute.fillna(value=0)\n",
    "# you could also use \"ls_impute = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0).fit_transform(ls_impute.values)\"\n",
    "# but, as is, it is a lot more verbose then I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) ADD POLY TERMS (not using sklearn because I don't want any interaction terms (way too many of them))\n",
    "\n",
    "floating_columns = [column for column in ls_impute.columns if column[0] != 'D' and column[-3:] != '_MI']\n",
    "floating_columns.remove(dependent_column)\n",
    "\n",
    "for column in floating_columns:\n",
    "    ls_impute[column + '_2'] = ls_impute[column]**2\n",
    "#     ls_impute[column + '_3'] = ls_impute[column]**3\n",
    "#     ls_impute[column + '_4'] = ls_impute[column]**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT UP THE DATA\n",
    "\n",
    "data_train, data_test = train_test_split(ls_impute, test_size=0.25, random_state=0)\n",
    "\n",
    "x_train = data_train.drop(dependent_column, axis=1)\n",
    "y_train = data_train[dependent_column]\n",
    "\n",
    "x_test = data_test.drop(dependent_column, axis=1)\n",
    "y_test = data_test[dependent_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (can be interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x195c692c0b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST DIFFERENT VALUES FOR N_COMPONENTS\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_tranform = PCA(random_state=0).fit(x_train)\n",
    "\n",
    "tot_evr_list = []\n",
    "for i in range(100):\n",
    "    tot_evr = np.sum(pca_tranform.explained_variance_ratio_[:i])\n",
    "    tot_evr_list.append(tot_evr)\n",
    "\n",
    "plt.plot(tot_evr_list)\n",
    "\n",
    "percent_threshold = 98\n",
    "n_comp_98 = np.argmax(np.array(tot_evr_list) > percent_threshold/100)\n",
    "n_comp_98\n",
    "\n",
    "# list(enumerate(tot_evr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM DATA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca_tranform = PCA(n_components=n_comp_98, random_state=0).fit(x_train)\n",
    "\n",
    "x_train_trans = pca_tranform.transform(x_train)\n",
    "x_test_trans = pca_tranform.transform(x_test)\n",
    "\n",
    "scaler = StandardScaler().fit(x_train_trans)\n",
    "x_train_trans = scaler.transform(x_train_trans)\n",
    "x_test_trans = scaler.transform(x_test_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SET VALUES IN CELL BELOW (VERY OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ONLY RUN THIS CELL IF YOU WANT TO TRAIN ON PCA TRANSFORMED DATA\n",
    "\n",
    "# x_train_dict = {i:x_train_trans[:, i] for i in range(x_test_trans.shape[1])}\n",
    "# x_train = pd.DataFrame(x_train_dict)\n",
    "\n",
    "# x_test_dict = {i:x_test_trans[:, i] for i in range(x_test_trans.shape[1])}\n",
    "# x_test = pd.DataFrame(x_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SET VALUES IN CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   23.5s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=4, penalty='l2', random_state=0,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################## REGRESSORS ##################################################\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# model = RidgeCV(cv=5)\n",
    "# model = RandomForestRegressor(n_estimators=100, max_depth=None, n_jobs=4, random_state=0, verbose=1)\n",
    "# model = GradientBoostingRegressor(n_estimators=100, max_depth=10, random_state=0, verbose=1)\n",
    "# model = LinearRegression()\n",
    "\n",
    "################################################## CLASSIFIERS ##################################################\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "model = LogisticRegressionCV(cv=5, n_jobs=4, verbose=1, random_state=0)\n",
    "# model = RandomForestClassifier(n_estimators=200, max_depth=15, n_jobs=4, random_state=0, verbose=1)\n",
    "# model = GradientBoostingClassifier(n_estimators=200, random_state=0, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegressionCV instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5366c83607f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-5366c83607f6>\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(model, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coef_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[1;32m--> 255\u001b[1;33m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegressionCV instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "# DISPLAY TRAINING INFORMATION (based on type of model)\n",
    "\n",
    "def eval_model(model, x_train, y_train, x_test, y_test):\n",
    "    train_pred = model.predict(x_train)\n",
    "    test_pred = model.predict(x_test)\n",
    "\n",
    "    if model_type == 'classifier':\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "        print('train acc: {}, test acc: {}'.format(train_acc, test_acc))\n",
    "\n",
    "        # THIS MAKES LITTLE SENSE IF USING PCA\n",
    "        print('*'*100)\n",
    "        for val in list(set(y_test)):\n",
    "            percent = np.sum(y_test == val)/y_test.shape[0]\n",
    "            print('val: {}, percent: {}'.format(val, percent))\n",
    "    else:\n",
    "        train_ev = explained_variance_score(y_train, train_pred)\n",
    "        test_ev = explained_variance_score(y_test, test_pred)\n",
    "        print('train ev: {}, test ev: {}'.format(train_ev, test_ev))\n",
    "\n",
    "\n",
    "eval_model(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D_home_ownership_MORTGAGE</th>\n",
       "      <td>0.0131198762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_home_ownership_OTHER</th>\n",
       "      <td>0.0508252686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_home_ownership_OWN</th>\n",
       "      <td>-0.0331884639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_home_ownership_RENT</th>\n",
       "      <td>-0.1054428677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_car</th>\n",
       "      <td>0.1989179913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_credit_card</th>\n",
       "      <td>0.2747045020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_debt_consolidation</th>\n",
       "      <td>0.1473002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_educational</th>\n",
       "      <td>-0.2302490441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_home_improvement</th>\n",
       "      <td>0.1240013536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_house</th>\n",
       "      <td>-0.0444104751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_major_purchase</th>\n",
       "      <td>0.3687233689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_medical</th>\n",
       "      <td>-0.1747291882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_moving</th>\n",
       "      <td>-0.0800428098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_other</th>\n",
       "      <td>-0.0045702526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_renewable_energy</th>\n",
       "      <td>-0.4090645563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_small_business</th>\n",
       "      <td>-0.5868094702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_vacation</th>\n",
       "      <td>-0.0584032383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_purpose_wedding</th>\n",
       "      <td>0.3999454238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_term_ 36 months</th>\n",
       "      <td>0.1941154426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_term_ 60 months</th>\n",
       "      <td>-0.2688016293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_verification_status_Not Verified</th>\n",
       "      <td>-0.0145331393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_verification_status_Source Verified</th>\n",
       "      <td>-0.0577021725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_verification_status_Verified</th>\n",
       "      <td>-0.0024508748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <td>0.7474770284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <td>-1.4946445156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>19.5877501766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <td>3.8718693654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_open_to_buy</th>\n",
       "      <td>2.2071580626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_util</th>\n",
       "      <td>2.5443979178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <td>1.2829490053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <td>-0.4899632968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <td>-0.5541941753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_amnt</th>\n",
       "      <td>2.8111238995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>-0.0368027556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <td>0.1790697348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length</th>\n",
       "      <td>-0.2994330848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <td>-5.0996003628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>1.9369274644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>-3.3632674020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>-2.1556558489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <td>0.5580388928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <td>-0.0414964221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
       "      <td>0.6573782762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <td>-1.4780568341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mort_acc</th>\n",
       "      <td>0.2911282926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <td>1.0725529772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <td>1.3143867369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <td>1.9083782399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_bc</th>\n",
       "      <td>0.2946596965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_bc_dlq</th>\n",
       "      <td>-0.2916829235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <td>-0.6727398813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_revol_delinq</th>\n",
       "      <td>-0.3197214312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <td>0.6272264266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_actv_bc_tl</th>\n",
       "      <td>2.2261362313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_actv_rev_tl</th>\n",
       "      <td>2.4146556007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bc_sats</th>\n",
       "      <td>-2.1716028078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bc_tl</th>\n",
       "      <td>0.0143430382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_il_tl</th>\n",
       "      <td>0.5315257928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_op_rev_tl</th>\n",
       "      <td>0.3523502640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_rev_accts</th>\n",
       "      <td>-0.2604045005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_rev_tl_bal_gt_0</th>\n",
       "      <td>-3.6766255933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sats</th>\n",
       "      <td>0.7207767045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <td>-1.0689749467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <td>-0.4928532544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <td>-0.3663677558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <td>-0.9717546601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc</th>\n",
       "      <td>0.7485860268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <td>-0.8889337266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <td>-1.3057919640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec</th>\n",
       "      <td>-2.8686637243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <td>1.1850914858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal</th>\n",
       "      <td>-1.3823251702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>-0.2444948493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade</th>\n",
       "      <td>-0.7338026963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax_liens</th>\n",
       "      <td>4.9321491522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>-1.0403975247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <td>-2.7758870933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <td>-0.6135926976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>1.1860711683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <td>-6.6028107486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bc_limit</th>\n",
       "      <td>0.8405756289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <td>3.9828802621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <td>6.6567479168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq_2</th>\n",
       "      <td>-1.5037612662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_open_past_24mths_2</th>\n",
       "      <td>0.7672620036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc_2</th>\n",
       "      <td>-1.3776087086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cur_bal_2</th>\n",
       "      <td>2.3665874728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_open_to_buy_2</th>\n",
       "      <td>-1.0647174883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_util_2</th>\n",
       "      <td>-2.6434875450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargeoff_within_12_mths_2</th>\n",
       "      <td>-3.2065424508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collections_12_mths_ex_med_2</th>\n",
       "      <td>-1.5020245121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs_2</th>\n",
       "      <td>1.7079596074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_amnt_2</th>\n",
       "      <td>-3.1521796629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti_2</th>\n",
       "      <td>-0.5491545514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_2</th>\n",
       "      <td>-0.7460069318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length_2</th>\n",
       "      <td>0.2389516967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths_2</th>\n",
       "      <td>2.8387903824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment_2</th>\n",
       "      <td>-1.9282718633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate_2</th>\n",
       "      <td>2.6229608447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt_2</th>\n",
       "      <td>1.4756117025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_il_acct_2</th>\n",
       "      <td>-0.7574803910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_rev_tl_op_2</th>\n",
       "      <td>0.7216149409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_rcnt_rev_tl_op_2</th>\n",
       "      <td>-0.4419732577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_rcnt_tl_2</th>\n",
       "      <td>2.7010643136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mort_acc_2</th>\n",
       "      <td>-0.0864368288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_delinq_2</th>\n",
       "      <td>-2.1754467943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_major_derog_2</th>\n",
       "      <td>-1.8333371354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_record_2</th>\n",
       "      <td>-1.7061558182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_bc_2</th>\n",
       "      <td>1.6452028653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_bc_dlq_2</th>\n",
       "      <td>0.3350839635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_inq_2</th>\n",
       "      <td>0.6677872225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_revol_delinq_2</th>\n",
       "      <td>0.9348080263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_accts_ever_120_pd_2</th>\n",
       "      <td>-0.6727549873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_actv_bc_tl_2</th>\n",
       "      <td>-4.9516781591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_actv_rev_tl_2</th>\n",
       "      <td>1.8743278245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bc_sats_2</th>\n",
       "      <td>3.5906697076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bc_tl_2</th>\n",
       "      <td>-1.7633496561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_il_tl_2</th>\n",
       "      <td>-1.0104339980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_op_rev_tl_2</th>\n",
       "      <td>-2.4038669822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_rev_accts_2</th>\n",
       "      <td>2.1202714851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_rev_tl_bal_gt_0_2</th>\n",
       "      <td>0.1880617383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sats_2</th>\n",
       "      <td>-0.0333464681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_120dpd_2m_2</th>\n",
       "      <td>-0.2393277254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_30dpd_2</th>\n",
       "      <td>-0.1636062941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_90g_dpd_24m_2</th>\n",
       "      <td>-3.3435882692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_op_past_12m_2</th>\n",
       "      <td>0.5885633119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_2</th>\n",
       "      <td>-1.3096263401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_nvr_dlq_2</th>\n",
       "      <td>0.3476837920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_bc_gt_75_2</th>\n",
       "      <td>0.9921347032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec_2</th>\n",
       "      <td>1.1607209812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec_bankruptcies_2</th>\n",
       "      <td>-0.0774751317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal_2</th>\n",
       "      <td>0.6226163697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util_2</th>\n",
       "      <td>-0.2106742343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_2</th>\n",
       "      <td>-0.0165661885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax_liens_2</th>\n",
       "      <td>-2.2920993625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt_2</th>\n",
       "      <td>2.4042520364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_cur_bal_2</th>\n",
       "      <td>2.2613313673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_hi_cred_lim_2</th>\n",
       "      <td>2.0717678510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc_2</th>\n",
       "      <td>-1.5758830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bal_ex_mort_2</th>\n",
       "      <td>-0.3594816727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bc_limit_2</th>\n",
       "      <td>-1.5647227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_il_high_credit_limit_2</th>\n",
       "      <td>-1.9965940451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rev_hi_lim_2</th>\n",
       "      <td>1.8158645519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            class 0\n",
       "D_home_ownership_MORTGAGE              0.0131198762\n",
       "D_home_ownership_OTHER                 0.0508252686\n",
       "D_home_ownership_OWN                  -0.0331884639\n",
       "D_home_ownership_RENT                 -0.1054428677\n",
       "D_purpose_car                          0.1989179913\n",
       "D_purpose_credit_card                  0.2747045020\n",
       "D_purpose_debt_consolidation           0.1473002083\n",
       "D_purpose_educational                 -0.2302490441\n",
       "D_purpose_home_improvement             0.1240013536\n",
       "D_purpose_house                       -0.0444104751\n",
       "D_purpose_major_purchase               0.3687233689\n",
       "D_purpose_medical                     -0.1747291882\n",
       "D_purpose_moving                      -0.0800428098\n",
       "D_purpose_other                       -0.0045702526\n",
       "D_purpose_renewable_energy            -0.4090645563\n",
       "D_purpose_small_business              -0.5868094702\n",
       "D_purpose_vacation                    -0.0584032383\n",
       "D_purpose_wedding                      0.3999454238\n",
       "D_term_ 36 months                      0.1941154426\n",
       "D_term_ 60 months                     -0.2688016293\n",
       "D_verification_status_Not Verified    -0.0145331393\n",
       "D_verification_status_Source Verified -0.0577021725\n",
       "D_verification_status_Verified        -0.0024508748\n",
       "acc_now_delinq                         0.7474770284\n",
       "acc_open_past_24mths                  -1.4946445156\n",
       "annual_inc                            19.5877501766\n",
       "avg_cur_bal                            3.8718693654\n",
       "bc_open_to_buy                         2.2071580626\n",
       "bc_util                                2.5443979178\n",
       "chargeoff_within_12_mths               1.2829490053\n",
       "collections_12_mths_ex_med            -0.4899632968\n",
       "delinq_2yrs                           -0.5541941753\n",
       "delinq_amnt                            2.8111238995\n",
       "dti                                   -0.0368027556\n",
       "earliest_cr_line                       0.1790697348\n",
       "emp_length                            -0.2994330848\n",
       "inq_last_6mths                        -5.0996003628\n",
       "installment                            1.9369274644\n",
       "int_rate                              -3.3632674020\n",
       "loan_amnt                             -2.1556558489\n",
       "mo_sin_old_il_acct                     0.5580388928\n",
       "mo_sin_old_rev_tl_op                  -0.0414964221\n",
       "mo_sin_rcnt_rev_tl_op                  0.6573782762\n",
       "mo_sin_rcnt_tl                        -1.4780568341\n",
       "mort_acc                               0.2911282926\n",
       "mths_since_last_delinq                 1.0725529772\n",
       "mths_since_last_major_derog            1.3143867369\n",
       "mths_since_last_record                 1.9083782399\n",
       "mths_since_recent_bc                   0.2946596965\n",
       "mths_since_recent_bc_dlq              -0.2916829235\n",
       "mths_since_recent_inq                 -0.6727398813\n",
       "mths_since_recent_revol_delinq        -0.3197214312\n",
       "num_accts_ever_120_pd                  0.6272264266\n",
       "num_actv_bc_tl                         2.2261362313\n",
       "num_actv_rev_tl                        2.4146556007\n",
       "num_bc_sats                           -2.1716028078\n",
       "num_bc_tl                              0.0143430382\n",
       "num_il_tl                              0.5315257928\n",
       "num_op_rev_tl                          0.3523502640\n",
       "num_rev_accts                         -0.2604045005\n",
       "num_rev_tl_bal_gt_0                   -3.6766255933\n",
       "num_sats                               0.7207767045\n",
       "num_tl_120dpd_2m                      -1.0689749467\n",
       "num_tl_30dpd                          -0.4928532544\n",
       "num_tl_90g_dpd_24m                    -0.3663677558\n",
       "num_tl_op_past_12m                    -0.9717546601\n",
       "open_acc                               0.7485860268\n",
       "pct_tl_nvr_dlq                        -0.8889337266\n",
       "percent_bc_gt_75                      -1.3057919640\n",
       "pub_rec                               -2.8686637243\n",
       "pub_rec_bankruptcies                   1.1850914858\n",
       "revol_bal                             -1.3823251702\n",
       "revol_util                            -0.2444948493\n",
       "sub_grade                             -0.7338026963\n",
       "tax_liens                              4.9321491522\n",
       "tot_coll_amt                          -1.0403975247\n",
       "tot_cur_bal                           -2.7758870933\n",
       "tot_hi_cred_lim                       -0.6135926976\n",
       "total_acc                              1.1860711683\n",
       "total_bal_ex_mort                     -6.6028107486\n",
       "total_bc_limit                         0.8405756289\n",
       "total_il_high_credit_limit             3.9828802621\n",
       "total_rev_hi_lim                       6.6567479168\n",
       "acc_now_delinq_2                      -1.5037612662\n",
       "acc_open_past_24mths_2                 0.7672620036\n",
       "annual_inc_2                          -1.3776087086\n",
       "avg_cur_bal_2                          2.3665874728\n",
       "bc_open_to_buy_2                      -1.0647174883\n",
       "bc_util_2                             -2.6434875450\n",
       "chargeoff_within_12_mths_2            -3.2065424508\n",
       "collections_12_mths_ex_med_2          -1.5020245121\n",
       "delinq_2yrs_2                          1.7079596074\n",
       "delinq_amnt_2                         -3.1521796629\n",
       "dti_2                                 -0.5491545514\n",
       "earliest_cr_line_2                    -0.7460069318\n",
       "emp_length_2                           0.2389516967\n",
       "inq_last_6mths_2                       2.8387903824\n",
       "installment_2                         -1.9282718633\n",
       "int_rate_2                             2.6229608447\n",
       "loan_amnt_2                            1.4756117025\n",
       "mo_sin_old_il_acct_2                  -0.7574803910\n",
       "mo_sin_old_rev_tl_op_2                 0.7216149409\n",
       "mo_sin_rcnt_rev_tl_op_2               -0.4419732577\n",
       "mo_sin_rcnt_tl_2                       2.7010643136\n",
       "mort_acc_2                            -0.0864368288\n",
       "mths_since_last_delinq_2              -2.1754467943\n",
       "mths_since_last_major_derog_2         -1.8333371354\n",
       "mths_since_last_record_2              -1.7061558182\n",
       "mths_since_recent_bc_2                 1.6452028653\n",
       "mths_since_recent_bc_dlq_2             0.3350839635\n",
       "mths_since_recent_inq_2                0.6677872225\n",
       "mths_since_recent_revol_delinq_2       0.9348080263\n",
       "num_accts_ever_120_pd_2               -0.6727549873\n",
       "num_actv_bc_tl_2                      -4.9516781591\n",
       "num_actv_rev_tl_2                      1.8743278245\n",
       "num_bc_sats_2                          3.5906697076\n",
       "num_bc_tl_2                           -1.7633496561\n",
       "num_il_tl_2                           -1.0104339980\n",
       "num_op_rev_tl_2                       -2.4038669822\n",
       "num_rev_accts_2                        2.1202714851\n",
       "num_rev_tl_bal_gt_0_2                  0.1880617383\n",
       "num_sats_2                            -0.0333464681\n",
       "num_tl_120dpd_2m_2                    -0.2393277254\n",
       "num_tl_30dpd_2                        -0.1636062941\n",
       "num_tl_90g_dpd_24m_2                  -3.3435882692\n",
       "num_tl_op_past_12m_2                   0.5885633119\n",
       "open_acc_2                            -1.3096263401\n",
       "pct_tl_nvr_dlq_2                       0.3476837920\n",
       "percent_bc_gt_75_2                     0.9921347032\n",
       "pub_rec_2                              1.1607209812\n",
       "pub_rec_bankruptcies_2                -0.0774751317\n",
       "revol_bal_2                            0.6226163697\n",
       "revol_util_2                          -0.2106742343\n",
       "sub_grade_2                           -0.0165661885\n",
       "tax_liens_2                           -2.2920993625\n",
       "tot_coll_amt_2                         2.4042520364\n",
       "tot_cur_bal_2                          2.2613313673\n",
       "tot_hi_cred_lim_2                      2.0717678510\n",
       "total_acc_2                           -1.5758830986\n",
       "total_bal_ex_mort_2                   -0.3594816727\n",
       "total_bc_limit_2                      -1.5647227400\n",
       "total_il_high_credit_limit_2          -1.9965940451\n",
       "total_rev_hi_lim_2                     1.8158645519"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAKE DATAFRAME FOR MODEL COEFFICIENTS (IF APPLICABLE)\n",
    "\n",
    "coef_df = pd.DataFrame(index=x_train.columns)\n",
    "\n",
    "for i in range(len(model.coef_)):\n",
    "    coef_df['class {}'.format(i)] = model.coef_[i]\n",
    "\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x195c254a400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x195c0bbb4e0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT COEFFICIENTS\n",
    "\n",
    "plt.figure(figsize=(6*5, 4*5))\n",
    "\n",
    "# THIS CAN WORK FOR MORE THAN BINARY CLASSES\n",
    "for col in coef_df.columns:\n",
    "    plt.plot(coef_df[col].values, '.', label=col)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding pred 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-bf4a3b9f9a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'classifier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-bf4a3b9f9a7e>\u001b[0m in \u001b[0;36mforward_selection\u001b[1;34m(model, model_type, x_train, y_train, num_pred)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_test_predictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mmodel_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_test_predictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1788\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m                       )\n\u001b[1;32m-> 1790\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m             for train, test in folds)\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    981\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    823\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[1;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    752\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"warnflag\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 199\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    201\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlog_logistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[0mz0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, explained_variance_score\n",
    "\n",
    "independent_columns\n",
    "def forward_selection(model, model_type, x_train, y_train, num_pred=5):\n",
    "    assert model_type in ['regressor', 'classifier']\n",
    "    def base_model():\n",
    "        return model\n",
    "    \n",
    "    best_scores = []\n",
    "    best_models = []\n",
    "    \n",
    "    all_predictors = set(independent_columns)\n",
    "    selected_good_predictors = set()\n",
    "    for i in range(num_pred):\n",
    "        print('finding pred {}'.format(i))\n",
    "        \n",
    "        possible_scores = []\n",
    "        possible_predictors = list(selected_good_predictors ^ all_predictors)\n",
    "        for predictor in possible_predictors:\n",
    "            current_test_predictors = list(selected_good_predictors) + [predictor]\n",
    "            \n",
    "            model = base_model()\n",
    "            model.fit(x_train[current_test_predictors], y_train)\n",
    "            model_pred = model.predict(x_train[current_test_predictors])\n",
    "            \n",
    "            if model_type == 'classifier':\n",
    "                score = accuracy_score(y_train, model_pred)\n",
    "            else:\n",
    "                score = explained_variance_score(y_train, model_pred)\n",
    "            possible_scores.append(score)\n",
    "        \n",
    "        best_predictor = possible_predictors[np.argmax(possible_scores)]\n",
    "        selected_good_predictors.add(best_predictor)\n",
    "        \n",
    "        best_models.append(list(selected_good_predictors))\n",
    "        best_scores.append(np.max(possible_scores))\n",
    "    return list(zip(best_scores, best_models))\n",
    "\n",
    "\n",
    "model = LogisticRegressionCV(cv=5, random_state=0)\n",
    "fs = forward_selection(model, 'classifier', x_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6212742548509702, ['annual_inc', 'sub_grade', 'D_term_ 36 months'])\n",
      "****************************************************************************************************\n",
      "train acc: 0.6212742548509702, test acc: 0.6258625862586259\n",
      "****************************************************************************************************\n",
      "val: 0.0, percent: 0.4990999099909991\n",
      "val: 1.0, percent: 0.5009000900090009\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegressionCV(cv=5)\n",
    "print(fs[-1])\n",
    "print('*'*100)\n",
    "\n",
    "preds = fs[-1][1]\n",
    "model.fit(x_train[preds], y_train)\n",
    "eval_model(model, x_train[preds], y_train, x_test[preds], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
