{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.15)\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "plt.rcParams['figure.figsize'] = (8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#LOAD LOANSTATS\n",
    "directory = '../../data/'\n",
    "ls = pd.read_hdf(directory + 'ls_CLEAN.h5', 'ls_CLEAN')\n",
    "ls.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin modeling, we set aside a test set that we will use later to evaluate the predictive quality of our investment strategy. We do this in a stratified fashion ensuring that the outcome classes (fully paid loans and not fully paid loans) are equally represented in the train and test sets. For the splitting algorithm, we use `sklearn`'s `train_test_split` function. This function creates random train and test subsets of the dataset. The flag `stratify` ensures that both classes are equally represented in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ls_train, ls_test = train_test_split(ls, test_size=0.15, stratify=ls['OUT_Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models used in the next sections assume that the features are on similar scales. To achieve this, we transform the numeric variables to a standard scale with mean 0 and standard deviation 1 using sklearn's `StandardScaler` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDENTIFY THE OUTCOME, DUMMY AND NUMERIC VARIABLES\n",
    "var_list = set(ls.columns)\n",
    "outcome_var_list = set(out_var for out_var in var_list if \"OUT_\" in out_var)\n",
    "dummy_var_list = set(dummy for dummy in var_list if \"D_\" in dummy)\n",
    "numeric_var_list = var_list - outcome_var_list - dummy_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SCALER\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE THE TRAINING SETS (fit_transform)\n",
    "train_vars_scaled = pd.DataFrame(scaler.fit_transform(ls_train[list(numeric_var_list)]),\n",
    "                                 index=ls_train.index, \n",
    "                                 columns=ls_train[list(numeric_var_list)].columns)\n",
    "feature_train = pd.concat([train_vars_scaled, \n",
    "                           ls_train[list(dummy_var_list)]], \n",
    "                          axis=1).sort_index(axis=1)\n",
    "outcome_train = ls_train[list(outcome_var_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logisitic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is a logistic regression on the outcome variable `OUT_class` which is the binary classification for loans are either fully repaid (1) or charged off (0). The flag `class_weight='balanced'` ensures that both classes are equally represented in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET TARGET VARIABLE 'OUT_Class'\n",
    "target_train = outcome_train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=10000,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=0,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=10000, class_weight='balanced')\n",
    "classifier.fit(feature_train, target_train)\n",
    "#target_predicted = classifier.predict(feature_test)\n",
    "#target_probabilities = classifier.predict_proba(feature_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6301\n",
      "Precision: 0.9156\n",
      "Recall: 0.6294\n"
     ]
    }
   ],
   "source": [
    "#MODEL EVALUATION\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#ACCURACY\n",
    "cross_val_accuracy = cross_val_score(classifier, feature_train, target_train, scoring='accuracy', cv=5).mean()\n",
    "print('Accuracy: {:.4}'.format(cross_val_accuracy))\n",
    "\n",
    "#PRECISION: true good loans / total predicted good loans\n",
    "precision = cross_val_score(classifier, feature_train, target_train, scoring='precision', cv=5).mean()\n",
    "print('Precision: {:.4}'.format(precision))\n",
    "\n",
    "#RECALL: true good loans / total actual good loans\n",
    "recall = cross_val_score(classifier, feature_train, target_train, scoring='recall', cv=5).mean()\n",
    "print('Recall: {:.4}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-473876e84076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m matrix = pd.DataFrame(confusion_matrix(target_test, target_predicted),\n\u001b[0m\u001b[1;32m      5\u001b[0m                       \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fully Repaid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Not Fully Repaid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       columns=['Fully Repaid', 'Not Fully Repaid'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_test' is not defined"
     ]
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = pd.DataFrame(confusion_matrix(target_test, target_predicted),\n",
    "                      index=['Fully Repaid', 'Not Fully Repaid'],\n",
    "                      columns=['Fully Repaid', 'Not Fully Repaid'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(matrix, annot=True, fmt='g', cbar=None, cmap='Blues')\n",
    "plt.title('Confusion Matrix of Binary Classification Predictions')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "ax.set_xticklabels(['Charged Off', 'Fully Repaid'], va='center')\n",
    "ax.set_yticklabels(['Charged Off', 'Fully Repaid'], va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC CURVE\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities)\n",
    "plt.title('Reciever Operating Characterisic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='ROC')\n",
    "plt.plot([0,1], ls='--',label='random')\n",
    "plt.plot([0,0],[1,0], c='.7', )\n",
    "plt.plot([1,1], c='.7', label='perfect')\n",
    "plt.legend()\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trees and Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
