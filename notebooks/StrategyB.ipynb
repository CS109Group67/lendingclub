{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.15)\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, RidgeCV, LassoCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "pd.options.display.max_rows = 50\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#LOAD LOANSTATS\n",
    "directory = '../../data/'\n",
    "ls = pd.read_hdf(directory + 'ls_CLEAN.h5', 'ls_CLEAN')\n",
    "ls.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ls_train, ls_test = train_test_split(ls, test_size=0.2, stratify=ls['OUT_Class'], random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B. Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SCALING\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#separate features and targets\n",
    "outcome_var_list = sorted(out_var for out_var in ls.columns if \"OUT_\" in out_var)\n",
    "\n",
    "#train features\n",
    "X_train = ls_train[sorted(set(ls.columns)-set(outcome_var_list))]\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "#test features\n",
    "X_test = ls_test[sorted(set(ls.columns)-set(outcome_var_list))]\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test),index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "#train targets\n",
    "y_train = ls_train[sorted(outcome_var_list)]\n",
    "OUT_Class_train = y_train.iloc[:,0]\n",
    "OUT_Principle_Repaid_Percentage_train = y_train.iloc[:,1]\n",
    "OUT_Monthly_Rate_Of_Return_train = y_train.iloc[:,2]\n",
    "\n",
    "#test targets\n",
    "y_test = ls_test[sorted(outcome_var_list)]\n",
    "OUT_Class_test = y_test.iloc[:,0]\n",
    "OUT_Principle_Repaid_Percentage_test = y_test.iloc[:,1]\n",
    "OUT_Monthly_Rate_Of_Return_test = y_test.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `OUT_Class`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B. Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "log_reg = LogisticRegressionCV(Cs=8, solver='lbfgs', max_iter=10000, class_weight='balanced', random_state=0, fit_intercept=False)\n",
    "log_reg.fit(X_train_scaled, OUT_Class_train)\n",
    "\n",
    "coeff_df['log_reg_2B'] = log_reg.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 `OUT_Principle_Repaid_Percentage`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "lasso_reg = LassoCV(fit_intercept=False)\n",
    "lasso_reg.fit(X_train_scaled, OUT_Principle_Repaid_Percentage_train)\n",
    "\n",
    "coeff_df['lasso_reg_3D'] = lasso_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `OUT_Monthly_Rate_Of_Return`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4D. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "lasso_reg = LassoCV(fit_intercept=False)\n",
    "lasso_reg.fit(X_train_scaled, OUT_Monthly_Rate_Of_Return_train)\n",
    "\n",
    "coeff_df['lasso_reg_4D'] = lasso_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. `Finding Best Predictors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, explained_variance_score\n",
    "\n",
    "# def forward_selection(model, model_type, x_train, y_train, num_pred=5):\n",
    "#     assert model_type in ['regressor', 'classifier']\n",
    "#     def base_model():\n",
    "#         return model\n",
    "    \n",
    "#     best_scores = []\n",
    "#     best_models = []\n",
    "    \n",
    "#     all_predictors = set(independent_columns)\n",
    "#     selected_good_predictors = set()\n",
    "#     for i in range(num_pred):\n",
    "#         print('finding pred {}'.format(i))\n",
    "        \n",
    "#         possible_scores = []\n",
    "#         possible_predictors = list(selected_good_predictors ^ all_predictors)\n",
    "#         for predictor in possible_predictors:\n",
    "#             current_test_predictors = list(selected_good_predictors) + [predictor]\n",
    "            \n",
    "#             model = base_model()\n",
    "#             model.fit(x_train[current_test_predictors], y_train)\n",
    "#             model_pred = model.predict(x_train[current_test_predictors])\n",
    "            \n",
    "#             if model_type == 'classifier':\n",
    "#                 score = accuracy_score(y_train, model_pred)\n",
    "#             else:\n",
    "#                 score = explained_variance_score(y_train, model_pred)\n",
    "#             possible_scores.append(score)\n",
    "        \n",
    "#         best_predictor = possible_predictors[np.argmax(possible_scores)]\n",
    "#         selected_good_predictors.add(best_predictor)\n",
    "        \n",
    "#         best_models.append(list(selected_good_predictors))\n",
    "#         best_scores.append(np.max(possible_scores))\n",
    "#     return list(zip(best_scores, best_models))\n",
    "\n",
    "\n",
    "# # fs = forward_selection(LogisticRegressionCV(cv=5, random_state=0), 'classifier', x_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df['sum'] = np.sum(np.abs(coeff_df[['log_reg_2B', 'lasso_reg_3D', 'lasso_reg_4D']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['installment', 'open_acc', 'total_bal_ex_mort',\n",
       "       'total_il_high_credit_limit', 'sub_grade'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_keep = 5\n",
    "\n",
    "ind = np.argsort(coeff_df['sum'].values)\n",
    "preds_keep = coeff_df['sum'][ind][-num_keep:].index.values\n",
    "preds_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "depths = {}\n",
    "for i in range(1, 10):\n",
    "    model = DecisionTreeRegressor(max_depth=i, random_state=0)\n",
    "    model.fit(X_train_scaled[preds_keep], OUT_Principle_Repaid_Percentage_train)\n",
    "    \n",
    "    model_pred = model.predict(X_test_scaled[preds_keep])\n",
    "    depths[i] = mean_absolute_error(OUT_Principle_Repaid_Percentage_test, model_pred)\n",
    "\n",
    "best_depth = min(depths, key=depths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014180342420874549"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(max_depth=best_depth, random_state=0)\n",
    "model.fit(X_train_scaled[preds_keep], OUT_Principle_Repaid_Percentage_train)\n",
    "\n",
    "model_pred = model.predict(X_test_scaled[preds_keep])\n",
    "model_loss = np.mean(np.abs(model_pred - OUT_Principle_Repaid_Percentage_test))\n",
    "model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014493387355386083"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(OUT_Principle_Repaid_Percentage_train)\n",
    "random_loss = np.mean(np.abs(mean - OUT_Principle_Repaid_Percentage_test))\n",
    "random_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0220759785074518"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_loss/model_loss - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 percent better then a random guessing the mean value... that's really not great..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
