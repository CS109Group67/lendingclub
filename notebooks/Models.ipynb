{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = '{:.10f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#LOAD LOANSTATS\n",
    "directory = '../../../data/'\n",
    "ls = pd.read_hdf(directory + 'LS_CLEAN.h5', 'LS_CLEAN')\n",
    "ls.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data preprocessing is needed in order to build and evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "var_list = set(ls.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Variable Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 outcome features were designed in the cleaning section and are already processed for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hide": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 OUT_Class\n",
      "2 OUT_Monthly_Rate_Of_Return\n",
      "3 OUT_Principle_Repaid_Percentage\n"
     ]
    }
   ],
   "source": [
    "#OUTCOME VARIABLES\n",
    "outcome_var_list = set(out_var for out_var in var_list if \"OUT_\" in out_var)\n",
    "for i, o in enumerate(sorted(outcome_var_list)):\n",
    "    print(\"{} {}\".format(i+1, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 dummy variables are used to indicate the borrower's state and home ownership, as well as the purpose, term and verification status of the loan. By using one-hot encoding and not discarding one dummy variable, we are implicitly adding an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  D_home_ownership_MORTGAGE\n",
      "2  D_home_ownership_OTHER\n",
      "3  D_home_ownership_OWN\n",
      "4  D_home_ownership_RENT\n",
      "5  D_purpose_car\n",
      "6  D_purpose_credit_card\n",
      "7  D_purpose_debt_consolidation\n",
      "8  D_purpose_educational\n",
      "9  D_purpose_home_improvement\n",
      "10 D_purpose_house\n",
      "11 D_purpose_major_purchase\n",
      "12 D_purpose_medical\n",
      "13 D_purpose_moving\n",
      "14 D_purpose_other\n",
      "15 D_purpose_renewable_energy\n",
      "16 D_purpose_small_business\n",
      "17 D_purpose_vacation\n",
      "18 D_purpose_wedding\n",
      "19 D_term_ 36 months\n",
      "20 D_term_ 60 months\n",
      "21 D_verification_status_Not Verified\n",
      "22 D_verification_status_Source Verified\n",
      "23 D_verification_status_Verified\n"
     ]
    }
   ],
   "source": [
    "#DUMMY VARIABLES\n",
    "dummy_var_list = set(dummy for dummy in var_list if \"D_\" in dummy)\n",
    "for i, d in enumerate(sorted(dummy_var_list)):\n",
    "    print(\"{:<2} {}\".format(i+1, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 numeric variables represent different loan and borrower characteristics. These variables will be transformed to a standard scale (section 1E) before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hide": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  acc_now_delinq\n",
      "2  acc_open_past_24mths\n",
      "3  annual_inc\n",
      "4  avg_cur_bal\n",
      "5  bc_open_to_buy\n",
      "6  bc_util\n",
      "7  chargeoff_within_12_mths\n",
      "8  collections_12_mths_ex_med\n",
      "9  delinq_2yrs\n",
      "10 delinq_amnt\n",
      "11 dti\n",
      "12 earliest_cr_line\n",
      "13 emp_length\n",
      "14 inq_last_6mths\n",
      "15 installment\n",
      "16 int_rate\n",
      "17 loan_amnt\n",
      "18 mo_sin_old_il_acct\n",
      "19 mo_sin_old_rev_tl_op\n",
      "20 mo_sin_rcnt_rev_tl_op\n",
      "21 mo_sin_rcnt_tl\n",
      "22 mort_acc\n",
      "23 mths_since_last_delinq\n",
      "24 mths_since_last_major_derog\n",
      "25 mths_since_last_record\n",
      "26 mths_since_recent_bc\n",
      "27 mths_since_recent_bc_dlq\n",
      "28 mths_since_recent_inq\n",
      "29 mths_since_recent_revol_delinq\n",
      "30 num_accts_ever_120_pd\n",
      "31 num_actv_bc_tl\n",
      "32 num_actv_rev_tl\n",
      "33 num_bc_sats\n",
      "34 num_bc_tl\n",
      "35 num_il_tl\n",
      "36 num_op_rev_tl\n",
      "37 num_rev_accts\n",
      "38 num_rev_tl_bal_gt_0\n",
      "39 num_sats\n",
      "40 num_tl_120dpd_2m\n",
      "41 num_tl_30dpd\n",
      "42 num_tl_90g_dpd_24m\n",
      "43 num_tl_op_past_12m\n",
      "44 open_acc\n",
      "45 pct_tl_nvr_dlq\n",
      "46 percent_bc_gt_75\n",
      "47 pub_rec\n",
      "48 pub_rec_bankruptcies\n",
      "49 revol_bal\n",
      "50 revol_util\n",
      "51 sub_grade\n",
      "52 tax_liens\n",
      "53 tot_coll_amt\n",
      "54 tot_cur_bal\n",
      "55 tot_hi_cred_lim\n",
      "56 total_acc\n",
      "57 total_bal_ex_mort\n",
      "58 total_bc_limit\n",
      "59 total_il_high_credit_limit\n",
      "60 total_rev_hi_lim\n"
     ]
    }
   ],
   "source": [
    "#NUMERIC VARIABLES\n",
    "numeric_var_list = var_list - outcome_var_list - dummy_var_list\n",
    "for i, n in enumerate(sorted(numeric_var_list)):\n",
    "    print(\"{:<2} {}\".format(i+1, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B. Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the `ls` dataset into a train and test part. We do this in a stratified fashion ensuring that the outcome classes (fully paid loans and not fully paid loans) are equally represented in each set. For the splitting algorithm, we use `sklearn`'s `train_test_split` function. This function creates random train and test subsets of the dataset. The flag `stratify` ensures that both classes are equally represented in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ls_train, ls_test = train_test_split(ls, test_size=0.2, stratify=ls['OUT_Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C. Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the models used later will assume all features are on similar scales. To achieve this, we use standardization to transform the numeric variables such that they have a mean of 0 and standard deviation of 1. We use `sklearn`'s `StandardScaler` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE THE TRAINING SETS (fit_transform)\n",
    "train_vars_scaled = pd.DataFrame(scaler.fit_transform(ls_train[list(numeric_var_list)]),\n",
    "                                 index=ls_train.index, \n",
    "                                 columns=ls_train[list(numeric_var_list)].columns)\n",
    "\n",
    "feature_train = pd.concat([train_vars_scaled, \n",
    "                           ls_train[list(dummy_var_list)]], \n",
    "                          axis=1).sort_index(axis=1)\n",
    "\n",
    "outcome_train = ls_train[list(outcome_var_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARDIZE THE TEST SET (transform)\n",
    "test_vars_scaled = pd.DataFrame(scaler.transform(ls_test[list(numeric_var_list)]),\n",
    "                                index=ls_test.index, \n",
    "                                columns=ls_test[list(numeric_var_list)].columns)\n",
    "\n",
    "feature_test = pd.concat([test_vars_scaled, \n",
    "                          ls_test[list(dummy_var_list)]], \n",
    "                         axis=1).sort_index(axis=1)\n",
    "\n",
    "outcome_test = ls_test[list(outcome_var_list)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C. Missing Value Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models we will use require that we handle the missing values in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIABLE                       MISSING\n",
      "acc_now_delinq                 0%\n",
      "acc_open_past_24mths           12%\n",
      "annual_inc                     0%\n",
      "avg_cur_bal                    17%\n",
      "bc_open_to_buy                 13%\n",
      "bc_util                        13%\n",
      "chargeoff_within_12_mths       0%\n",
      "collections_12_mths_ex_med     0%\n",
      "delinq_2yrs                    0%\n",
      "delinq_amnt                    0%\n",
      "earliest_cr_line               0%\n",
      "emp_length                     5%\n",
      "inq_last_6mths                 0%\n",
      "mo_sin_old_il_acct             20%\n",
      "mo_sin_old_rev_tl_op           17%\n",
      "mo_sin_rcnt_rev_tl_op          17%\n",
      "mo_sin_rcnt_tl                 17%\n",
      "mort_acc                       12%\n",
      "mths_since_last_delinq         53%\n",
      "mths_since_last_major_derog    78%\n",
      "mths_since_last_record         86%\n",
      "mths_since_recent_bc           13%\n",
      "mths_since_recent_bc_dlq       79%\n",
      "mths_since_recent_inq          21%\n",
      "mths_since_recent_revol_delinq 70%\n",
      "num_accts_ever_120_pd          17%\n",
      "num_actv_bc_tl                 17%\n",
      "num_actv_rev_tl                17%\n",
      "num_bc_sats                    14%\n",
      "num_bc_tl                      17%\n",
      "num_il_tl                      17%\n",
      "num_op_rev_tl                  17%\n",
      "num_rev_accts                  17%\n",
      "num_rev_tl_bal_gt_0            17%\n",
      "num_sats                       14%\n",
      "num_tl_120dpd_2m               19%\n",
      "num_tl_30dpd                   17%\n",
      "num_tl_90g_dpd_24m             17%\n",
      "num_tl_op_past_12m             17%\n",
      "open_acc                       0%\n",
      "pct_tl_nvr_dlq                 17%\n",
      "percent_bc_gt_75               13%\n",
      "pub_rec                        0%\n",
      "pub_rec_bankruptcies           0%\n",
      "revol_util                     0%\n",
      "tax_liens                      0%\n",
      "tot_coll_amt                   17%\n",
      "tot_cur_bal                    17%\n",
      "tot_hi_cred_lim                17%\n",
      "total_acc                      0%\n",
      "total_bal_ex_mort              12%\n",
      "total_bc_limit                 12%\n",
      "total_il_high_credit_limit     17%\n",
      "total_rev_hi_lim               17%\n"
     ]
    }
   ],
   "source": [
    "print('{:<30} {}'.format('VARIABLE', 'MISSING'))\n",
    "for var in sorted(numeric_var_list):\n",
    "    if ls[var].isnull().sum() > 0:\n",
    "        print('{:<30} {:.0%}'.format(var, ls[var].isnull().sum()/len(ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84036"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outcome_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michal/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-7a4b50aacbb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_logreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1284\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 568\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "model_logreg = logreg.fit(feature_train, outcome_test.iloc[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826096    1\n",
       "861888    1\n",
       "353431    0\n",
       "837420    0\n",
       "383519    1\n",
       "191341    1\n",
       "414683    1\n",
       "4479      1\n",
       "242956    1\n",
       "201355    1\n",
       "343151    1\n",
       "30033     0\n",
       "860846    1\n",
       "394910    1\n",
       "138958    1\n",
       "117233    1\n",
       "422825    1\n",
       "836949    1\n",
       "35194     1\n",
       "346527    1\n",
       "273750    1\n",
       "75694     1\n",
       "14420     1\n",
       "103244    1\n",
       "203790    1\n",
       "320556    1\n",
       "32205     1\n",
       "225221    1\n",
       "204021    1\n",
       "354487    1\n",
       "250947    1\n",
       "425511    1\n",
       "46002     1\n",
       "34269     1\n",
       "403491    0\n",
       "456816    1\n",
       "838911    1\n",
       "91856     1\n",
       "209269    1\n",
       "124605    1\n",
       "164613    1\n",
       "828790    1\n",
       "5910      1\n",
       "378715    1\n",
       "220358    1\n",
       "462001    1\n",
       "100556    1\n",
       "101363    1\n",
       "45130     0\n",
       "38938     1\n",
       "         ..\n",
       "396924    1\n",
       "175172    1\n",
       "863921    1\n",
       "825545    1\n",
       "110803    1\n",
       "23545     0\n",
       "404221    1\n",
       "102236    1\n",
       "85349     1\n",
       "97780     1\n",
       "147664    0\n",
       "10037     1\n",
       "11146     1\n",
       "827718    0\n",
       "412779    0\n",
       "26403     1\n",
       "23375     1\n",
       "129976    1\n",
       "384366    1\n",
       "258843    1\n",
       "199846    1\n",
       "37901     1\n",
       "220980    1\n",
       "283969    1\n",
       "335810    1\n",
       "19326     1\n",
       "158762    1\n",
       "297378    1\n",
       "198052    0\n",
       "111007    1\n",
       "819836    1\n",
       "273201    0\n",
       "302344    1\n",
       "847887    1\n",
       "156814    1\n",
       "256614    0\n",
       "881227    1\n",
       "104929    1\n",
       "116962    1\n",
       "375098    1\n",
       "283529    1\n",
       "111082    0\n",
       "212314    1\n",
       "125986    1\n",
       "33552     1\n",
       "330145    1\n",
       "419592    1\n",
       "848041    1\n",
       "197836    0\n",
       "821625    1\n",
       "Name: OUT_Class, Length: 84036, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees and Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
