{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, explained_variance_score\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = '{:.10f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#LOAD LOANSTATS\n",
    "directory = '../../../data/'\n",
    "ls = pd.read_hdf(directory + 'LS_CLEAN.h5', 'LS_CLEAN')\n",
    "ls.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe contains dependent outcome variables, independent dummy variables and indepenent numeric variables. Some data preprocessing is needed in order to build and evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "var_list = set(ls.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Outcome Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 outcome features were designed in the cleaning section and are already processed for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hide": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 OUT_Class\n",
      "2 OUT_Monthly_Rate_Of_Return\n",
      "3 OUT_Principle_Repaid_Percentage\n"
     ]
    }
   ],
   "source": [
    "#OUTCOME VARIABLES\n",
    "outcome_var_list = set(out_var for out_var in var_list if \"OUT_\" in out_var)\n",
    "for i, o in enumerate(sorted(outcome_vars)):\n",
    "    print(\"{} {}\".format(i+1, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B. Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 dummy variables are used to indicate the borrower's state and home ownership, as well as the purpose, term and verification status of the loan. By using one-hot encoding and not discarding one dummy variable, we are implicitly adding an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hide": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  D_home_ownership_MORTGAGE\n",
      "2  D_home_ownership_OTHER\n",
      "3  D_home_ownership_OWN\n",
      "4  D_home_ownership_RENT\n",
      "5  D_purpose_car\n",
      "6  D_purpose_credit_card\n",
      "7  D_purpose_debt_consolidation\n",
      "8  D_purpose_educational\n",
      "9  D_purpose_home_improvement\n",
      "10 D_purpose_house\n",
      "11 D_purpose_major_purchase\n",
      "12 D_purpose_medical\n",
      "13 D_purpose_moving\n",
      "14 D_purpose_other\n",
      "15 D_purpose_renewable_energy\n",
      "16 D_purpose_small_business\n",
      "17 D_purpose_vacation\n",
      "18 D_purpose_wedding\n",
      "19 D_term_ 36 months\n",
      "20 D_term_ 60 months\n",
      "21 D_verification_status_Not Verified\n",
      "22 D_verification_status_Source Verified\n",
      "23 D_verification_status_Verified\n"
     ]
    }
   ],
   "source": [
    "#DUMMY VARIABLES\n",
    "dummy_var_list = set(dummy for dummy in var_list if \"D_\" in dummy)\n",
    "for i, d in enumerate(sorted(dummy_vars)):\n",
    "    print(\"{:<2} {}\".format(i+1, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C. Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 numeric variables represent different loan characteristics and borrower credit history. These variables will be transformed to a standard scale (section 1E) before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hide": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  acc_now_delinq\n",
      "2  acc_open_past_24mths\n",
      "3  annual_inc\n",
      "4  avg_cur_bal\n",
      "5  bc_open_to_buy\n",
      "6  bc_util\n",
      "7  chargeoff_within_12_mths\n",
      "8  collections_12_mths_ex_med\n",
      "9  delinq_2yrs\n",
      "10 delinq_amnt\n",
      "11 dti\n",
      "12 earliest_cr_line\n",
      "13 emp_length\n",
      "14 inq_last_6mths\n",
      "15 installment\n",
      "16 int_rate\n",
      "17 loan_amnt\n",
      "18 mo_sin_old_il_acct\n",
      "19 mo_sin_old_rev_tl_op\n",
      "20 mo_sin_rcnt_rev_tl_op\n",
      "21 mo_sin_rcnt_tl\n",
      "22 mort_acc\n",
      "23 mths_since_last_delinq\n",
      "24 mths_since_last_major_derog\n",
      "25 mths_since_last_record\n",
      "26 mths_since_recent_bc\n",
      "27 mths_since_recent_bc_dlq\n",
      "28 mths_since_recent_inq\n",
      "29 mths_since_recent_revol_delinq\n",
      "30 num_accts_ever_120_pd\n",
      "31 num_actv_bc_tl\n",
      "32 num_actv_rev_tl\n",
      "33 num_bc_sats\n",
      "34 num_bc_tl\n",
      "35 num_il_tl\n",
      "36 num_op_rev_tl\n",
      "37 num_rev_accts\n",
      "38 num_rev_tl_bal_gt_0\n",
      "39 num_sats\n",
      "40 num_tl_120dpd_2m\n",
      "41 num_tl_30dpd\n",
      "42 num_tl_90g_dpd_24m\n",
      "43 num_tl_op_past_12m\n",
      "44 open_acc\n",
      "45 pct_tl_nvr_dlq\n",
      "46 percent_bc_gt_75\n",
      "47 pub_rec\n",
      "48 pub_rec_bankruptcies\n",
      "49 revol_bal\n",
      "50 revol_util\n",
      "51 sub_grade\n",
      "52 tax_liens\n",
      "53 tot_coll_amt\n",
      "54 tot_cur_bal\n",
      "55 tot_hi_cred_lim\n",
      "56 total_acc\n",
      "57 total_bal_ex_mort\n",
      "58 total_bc_limit\n",
      "59 total_il_high_credit_limit\n",
      "60 total_rev_hi_lim\n"
     ]
    }
   ],
   "source": [
    "#NUMERIC VARIABLES\n",
    "numeric_var_list = var_list - outcome_var_list - dummy_var_list\n",
    "for i, n in enumerate(sorted(numeric_vars)):\n",
    "    print(\"{:<2} {}\".format(i+1, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D. Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the `ls` dataset into a train and test part. We do this in a 'stratified' fashion ensuring that the outcome classes (fully paid loans and not fully paid loans) are equally represented in each set. For the splitting algorithm, we use `sklearn`'s `train_test_split` function. This function creates random train and test subsets of the dataset. The flag `stratify` ensures that both classes are equally represented in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ls_train, ls_test = train_test_split(ls, test_size=0.2, stratify=ls['OUT_Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1E. Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the models used later will assume all features are on similar scales. To achieve this, we use standardization to transform the numeric variables such that they have a mean of 0 and standard deviation of 1. We use `sklearn`'s `StandardScaler` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars_scaled = scaler.fit_transform(ls_train[list(numeric_var_list)])\n",
    "train_vars_scaled = pd.DataFrame(train_vars_scaled, \n",
    "                                 index=ls_train.index, \n",
    "                                 columns=ls_train[list(numeric_var_list)].columns)\n",
    "ls_train_scaled = pd.concat(objs=[train_vars_scaled,\n",
    "                                  ls_train[list(outcome_var_list)],\n",
    "                                  ls_train[list(dummy_var_list)]],\n",
    "                            axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vars_scaled = scaler.transform(ls_test[list(numeric_var_list)])\n",
    "test_vars_scaled = pd.DataFrame(test_vars_scaled, \n",
    "                                index=ls_test.index, \n",
    "                                columns=ls_test[list(numeric_var_list)].columns)\n",
    "ls_test_scaled = pd.concat(objs=[test_vars_scaled,\n",
    "                                ls_test[list(outcome_var_list)],\n",
    "                                ls_test[list(dummy_var_list)]],\n",
    "                           axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees and Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
