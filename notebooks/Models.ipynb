{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.15)\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "plt.rcParams['figure.figsize'] = (8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "#LOAD LOANSTATS\n",
    "directory = '../../../data/'\n",
    "ls = pd.read_hdf(directory + 'LS_CLEAN.h5', 'LS_CLEAN')\n",
    "ls.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin modeling, we set aside a test set that we will use later to evaluate the predictive quality of our investment strategy. We do this in a stratified fashion ensuring that the outcome classes (fully paid loans and not fully paid loans) are equally represented in the train and test sets. For the splitting algorithm, we use `sklearn`'s `train_test_split` function. This function creates random train and test subsets of the dataset. The flag `stratify` ensures that both classes are equally represented in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ls_train, ls_test = train_test_split(ls, test_size=0.15, stratify=ls['OUT_Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models used in the next sections assume that the features are on similar scales. To achieve this, we transform the numeric variables to a standard scale with mean 0 and standard deviation 1 using sklearn's `StandardScaler` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDENTIFY THE OUTCOME, DUMMY AND NUMERIC VARIABLES\n",
    "var_list = set(ls.columns)\n",
    "outcome_var_list = set(out_var for out_var in var_list if \"OUT_\" in out_var)\n",
    "dummy_var_list = set(dummy for dummy in var_list if \"D_\" in dummy)\n",
    "numeric_var_list = var_list - outcome_var_list - dummy_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SCALER\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE THE TRAINING SETS (fit_transform)\n",
    "train_vars_scaled = pd.DataFrame(scaler.fit_transform(ls_train[list(numeric_var_list)]),\n",
    "                                 index=ls_train.index, \n",
    "                                 columns=ls_train[list(numeric_var_list)].columns)\n",
    "feature_train = pd.concat([train_vars_scaled, \n",
    "                           ls_train[list(dummy_var_list)]], \n",
    "                          axis=1).sort_index(axis=1)\n",
    "outcome_train = ls_train[list(outcome_var_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logisitic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is a logistic regression on the outcome variable `OUT_class` which is the binary classification for loans are either fully repaid (1) or charged off (0). The flag `class_weight='balanced'` ensures that both classes are equally represented in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET TARGET VARIABLE 'OUT_Class'\n",
    "target_train = outcome_train.iloc[:,1]\n",
    "target_test = outcome_test.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=10000, class_weight='balanced')\n",
    "classifier.fit(feature_train, target_train)\n",
    "target_predicted = classifier.predict(feature_test)\n",
    "target_probabilities = classifier.predict_proba(feature_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL EVALUATION\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#ACCURACY\n",
    "cross_val_accuracy = cross_val_score(classifier, feature_train, target_train, scoring='accuracy', cv=5).mean()\n",
    "print('Accuracy: {:.4}'.format(cross_val_accuracy))\n",
    "\n",
    "#PRECISION: true good loans / total predicted good loans\n",
    "precision = cross_val_score(classifier, feature_train, target_train, scoring='precision', cv=5).mean()\n",
    "print('Precision: {:.4}'.format(precision))\n",
    "\n",
    "#RECALL: true good loans / total actual good loans\n",
    "recall = cross_val_score(classifier, feature_train, target_train, scoring='recall', cv=5).mean()\n",
    "print('Recall: {:.4}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = pd.DataFrame(confusion_matrix(target_test, target_predicted),\n",
    "                      index=['Fully Repaid', 'Not Fully Repaid'],\n",
    "                      columns=['Fully Repaid', 'Not Fully Repaid'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(matrix, annot=True, fmt='g', cbar=None, cmap='Blues')\n",
    "plt.title('Confusion Matrix of Binary Classification Predictions')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "ax.set_xticklabels(['Charged Off', 'Fully Repaid'], va='center')\n",
    "ax.set_yticklabels(['Charged Off', 'Fully Repaid'], va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC CURVE\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities)\n",
    "plt.title('Reciever Operating Characterisic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='ROC')\n",
    "plt.plot([0,1], ls='--',label='random')\n",
    "plt.plot([0,0],[1,0], c='.7', )\n",
    "plt.plot([1,1], c='.7', label='perfect')\n",
    "plt.legend()\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees and Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
