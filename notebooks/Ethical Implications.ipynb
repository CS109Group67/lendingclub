{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethical Implications\n",
    "\n",
    "The Equal Credit Opportunity Act (ECOA) is a federal law that prohibits lending entities (both institutions and people) from discriminating \"on the basis of race, color, religion, national origin, sex, marital status, age,\" or because the prospective borrower receives public assistance. Lenders are, however, permitted to consider an applicant's \"income, expenses, debts, and credit history\" in evaluating the applicant's probability of repaying the debt to decide whether to accept or reject loan applications and to determine loan terms. Nevertheless, differential treatment by race, color, religion, national origin, sex, etc can still arise even when an institution or person is not explicitly discriminating based on those characteristics. Thus, we want to assess whether we see evidence of discrimination in LendingClub's acceptances and rejections of loan applications or in the terms it sets for accepted loans. In addition, we want to evaluate whether our proposed investing strategy results in differential treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Review\n",
    "\n",
    "To inform our approach, we surveyed existing research of how predictive algorithms can result in discrimination and methods for addressing it.\n",
    "\n",
    "#### Sweeney, L. \"Discrimination in Online Ad Delivery\". Communications of the ACM, May 2013, Vol. 56 No. 5, Pages 44-54.\n",
    "\n",
    "#### Datta, A., Tschantz, M.C., and Datta, A. \"Automated Experiments on Ad Privacy Settings: A Tale of Opacity, Choice, and Discrimination\". Proceedings on Privacy Enhancing Technologies 2015; 2015 (1):92–112.\n",
    "\n",
    "#### Ribeiro, M.T., Singh, S., and Guestrin, C. \"Why Should I Trust You?: Explaining the Predictions of Any Classifier\". Association for Computing Machinery. KDD 2016 San Francisco, CA, USA.\n",
    "\n",
    "#### Datta, A., Sen, S., and Zick, Y. \"Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems\". Carnegie Mellon University, Pittsburgh, USA.\n",
    "\n",
    "#### Yang, K., Stoyanovich, J., Abolfazl, A., Howe, B., Jagadish, H.V., and Miklau, G. \"A Nutritional Label for Rankings\". Association for Computing Machinery. SIGMOD’18, June 10–15, 2018, Houston, TX, USA.\n",
    "\n",
    "#### Skeem, J.L. and Lowenkamp, C. \"Risk, Race, & Recidivism: Predictive Bias and Disparate Impact\". June 14, 2016.\n",
    "\n",
    "#### Olver, M., Stockdale, K.C., and Wormith, J. \"Thirty Years of Research on the Level of Service Scales: A Meta-Analytic Examination of Predictive Accuracy and Sources of Variability\". Psychological Assessment (2013). 26. 10.1037/a0035080. \n",
    "\n",
    "#### Angwin, J., Larson, J., Mattu, S., and Kirchner, L. \"Machine Bias\". ProPublica. May 23, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Data Description and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
